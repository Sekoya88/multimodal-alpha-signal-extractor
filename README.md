# ğŸ§  Multimodal Alpha-Signal Extractor

> **Any-to-Any** system that analyzes financial charts (Images) + market news (Text) to generate structured JSON trading signals.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PIPELINE ARCHITECTURE                     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Chart    â”‚â”€â”€â”€â–¶â”‚  Ollama VLM  â”‚â”€â”€â”€â–¶â”‚  VLM Trading     â”‚  â”‚
â”‚  â”‚ (Image)  â”‚    â”‚  (Llama3.2V) â”‚    â”‚  Signal (JSON)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                               â”‚ merge      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ News     â”‚â”€â”€â”€â–¶â”‚  Ollama LLM  â”‚â”€â”€â”€â–¶â”‚  Final Trading   â”‚  â”‚
â”‚  â”‚ (Text)   â”‚    â”‚  (Llama3-8b) â”‚    â”‚  Decision (JSON) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LangChain Orchestrator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Stack Technique

| Composant | Outil | RÃ´le |
|-----------|-------|------|
| Fine-tuning | **Unsloth** + QLoRA | Adapter Qwen2.5-VL-3B sur dataset multimodal (Google Colab T4) |
| InfÃ©rence VLM | **Ollama** (M4) / **llama-cpp** (Metal M4) | Servir le VLM localement via API ou GGUF direct |
| Orchestration | **LangChain** | Prompt multimodal, chaÃ®nage async, parsing Pydantic |
| Sentiment texte | **Ollama** | Extraction de sentiment via Llama3-8b local |

## ğŸ—‚ Structure du Projet

```
multimodal-alpha-signal-extractor/
â”œâ”€â”€ config.py                   # Configuration centralisÃ©e (dataclasses)
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ 01_generate_dataset.py      # Ã‰tape 1 : GÃ©nÃ©ration du dataset synthÃ©tique
â”œâ”€â”€ 02_finetune_vlm.py          # Ã‰tape 2a : Fine-tuning (CUDA â€” vLLM target)
â”œâ”€â”€ 02_finetune_colab.py        # Ã‰tape 2b : Fine-tuning (Google Colab T4)
â”œâ”€â”€ 03_serve_vllm.py            # Ã‰tape 3a : Serveur vLLM (CUDA)
â”œâ”€â”€ 03_serve_ollama.py          # Ã‰tape 3b : Serveur Ollama (Apple Silicon M4)
â”œâ”€â”€ 04_langchain_pipeline.py    # Ã‰tape 4 : Orchestrateur LangChain
â”œâ”€â”€ decision.json               # Dernier output du pipeline
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ training_data.jsonl     # 84 samples multimodaux
â”‚   â””â”€â”€ demo_chart.png          # Chart de test extrait du dataset
â””â”€â”€ models/                     # Checkpoints (aprÃ¨s fine-tuning)
```

## ğŸš€ Quick Start (MacBook M4)

### 1. PrÃ©requis

```bash
# Ollama (dÃ©jÃ  installÃ© si vous lisez ceci)
ollama pull llama3.2-vision:11b
ollama pull llama3:8b

# Python
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# (Optionnel) Pour infÃ©rence GGUF directe avec le modÃ¨le fine-tunÃ© sur Apple Silicon
CMAKE_ARGS="-DGGML_METAL=on" pip install llama-cpp-python --force-reinstall --no-cache-dir
```

### 2. GÃ©nÃ©rer le Dataset

```bash
python 01_generate_dataset.py
# â†’ 84 samples | 9.9 MB | AAPL 2024-2026
```

### 3. Fine-Tuner (Google Colab)

1. Upload `training_data.jsonl` sur Google Colab
2. `pip install unsloth` dans Colab (Runtime â†’ T4 GPU)
3. `python 02_finetune_colab.py`
4. TÃ©lÃ©charger le `.gguf` sur votre Mac
5. ExÃ©cuter le pipeline via `llama_cpp` (Metal) en configurant `config.py`

### 4. ExÃ©cuter le Pipeline

```bash
# Mode dÃ©mo (utilise un chart du dataset)
python 04_langchain_pipeline.py --demo

# Mode custom
python 04_langchain_pipeline.py \
    --image mon_chart.png \
    --news "Apple dÃ©passe les attentes avec +12% de CA" \
    --output signal.json
```

## âœ… RÃ©sultat d'ExÃ©cution (M4, 24 GB)

```json
{
  "final_action": "BUY",
  "final_confidence": 0.80,
  "vlm_signal": {
    "action": "BUY",
    "confidence": 0.8,
    "entry_price": 180.0,
    "stop_loss": 175.0,
    "take_profit": 190.0
  },
  "sentiment": {
    "sentiment": "BULLISH",
    "intensity": 0.8,
    "key_factors": ["record-breaking results", "12% revenue growth"]
  },
  "meta": {
    "vlm_model": "llama3.2-vision:11b",
    "sentiment_model": "llama3:8b",
    "signals_aligned": true,
    "platform": "Apple Silicon M4"
  }
}
```

## âš™ï¸ Configuration

`config.py` â€” Toutes les configs en `dataclass` immuables :

| Config | Description |
|--------|-------------|
| `DatasetConfig` | Ticker, pÃ©riode, fenÃªtre, indicateurs |
| `TrainingConfig` | ModÃ¨le de base, LoRA rank, hyperparamÃ¨tres |
| `VLLMConfig` | Host, port, GPU utilization (CUDA only) |
| `PipelineConfig` | `vlm_provider` (ollama/vllm), endpoints, retry |

Pour switcher entre Ollama et vLLM, modifiez `vlm_provider` dans `config.py` :

```python
vlm_provider: str = "ollama"  # ou "vllm" sur machine CUDA
```

## ğŸ“„ License

MIT
